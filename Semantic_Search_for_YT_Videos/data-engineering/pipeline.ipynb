{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL of YouTube Video Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import requests\n",
    "import json\n",
    "import polars as pl\n",
    "from my_sk import my_key\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getVideoRecords(response: requests.models.Response) -> list:\n",
    "    \"\"\"\n",
    "        Function to extract YouTube video from GET request response\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize list to store data from page results\n",
    "    video_record_list = []\n",
    "\n",
    "    for raw_item in json.loads(response.text)['items']:\n",
    "\n",
    "        # only execute for youtube videos\n",
    "        if raw_item['id']['kind'] != \"youtube#video\":\n",
    "            continue\n",
    "\n",
    "        # extract relevant data\n",
    "        Video_record = {}\n",
    "        Video_record['video_id'] = raw_item['id']['videoId']\n",
    "        Video_record['datetime'] = raw_item['snippet']['publishedAt']\n",
    "        Video_record['title'] = raw_item['snippet']['title']\n",
    "\n",
    "        # append record to list\n",
    "        video_record_list.append(Video_record)\n",
    "\n",
    "    return video_record_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(transcript: list) -> str:\n",
    "    \"\"\"\n",
    "        Function to extract text from transcript dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    text_list = [transcript[i]['text'] for i in range(len(transcript))]\n",
    "    return ''.join(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract videos IDs (+ datetime, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define channel ID\n",
    "channel_id = 'UCa9gErQ9AE5jT2DZLjXBIdA'\n",
    "# UCsT0YIqwnpJCM-mx7-gSA4Q : TEDx\n",
    "# \n",
    "\n",
    "# define url for API\n",
    "url = 'https://www.googleapis.com/youtube/v3/search'\n",
    "\n",
    "# initialize page token \n",
    "page_token = None\n",
    "\n",
    "# initialize list to store video data\n",
    "video_record_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract video data across multiple search result pages\n",
    "\n",
    "while page_token != 0:\n",
    "    # define parameters for API call\n",
    "    params = {'key': my_key, 'channelId': channel_id, 'part': [\"snippet\",\"id\"], 'order':\"date\", 'maxResults':50, 'pageToken':page_token}\n",
    "\n",
    "    # make get request\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # append video data from page results to list\n",
    "    video_record_list += getVideoRecords(response)\n",
    "\n",
    "    try: \n",
    "        # get next page token\n",
    "        page_token = json.loads(response.text)['nextPageToken']\n",
    "    except:\n",
    "        # if no next page token, kill while loop\n",
    "        page_token = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────────────┬──────────────────────┬─────────────────────────────────┐\n",
      "│ video_id    ┆ datetime             ┆ title                           │\n",
      "│ ---         ┆ ---                  ┆ ---                             │\n",
      "│ str         ┆ str                  ┆ str                             │\n",
      "╞═════════════╪══════════════════════╪═════════════════════════════════╡\n",
      "│ pJ_nCklQ65w ┆ 2024-05-18T15:24:22Z ┆ How to Deploy ML Solutions wit… │\n",
      "│ 6qCrvlHRhcM ┆ 2024-05-11T15:00:08Z ┆ How to Build ML Solutions (w/ … │\n",
      "│ OnIQrDiTtRM ┆ 2024-05-03T12:40:43Z ┆ How to Build Data Pipelines fo… │\n",
      "│ eayzAZltV9U ┆ 2024-04-29T13:54:55Z ┆ 4 Lessons from AI Consulting #… │\n",
      "│ 03x2oYg9oME ┆ 2024-04-25T15:16:00Z ┆ How to Manage Data Science Pro… │\n",
      "└─────────────┴──────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# store data in polars dataframe\n",
    "df = pl.DataFrame(video_record_list)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list to score video captions\n",
    "transcript_text_list = []\n",
    "\n",
    "# loop through each row of dataframe\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # try to extract captions\n",
    "    try:\n",
    "        # get transcript\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(df['video_id'][i])\n",
    "        # extract text transcript\n",
    "        transcript_text = extract_text(transcript)\n",
    "    # if not captions available set as n/a\n",
    "    except:\n",
    "        transcript_text = \"n/a\"\n",
    "\n",
    "    # append transcript text to list \n",
    "    transcript_text_list.append(transcript_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────┬──────────────────────┬──────────────────────────────┬──────────────────────────────┐\n",
      "│ video_id    ┆ datetime             ┆ title                        ┆ transcript                   │\n",
      "│ ---         ┆ ---                  ┆ ---                          ┆ ---                          │\n",
      "│ str         ┆ str                  ┆ str                          ┆ str                          │\n",
      "╞═════════════╪══════════════════════╪══════════════════════════════╪══════════════════════════════╡\n",
      "│ pJ_nCklQ65w ┆ 2024-05-18T15:24:22Z ┆ How to Deploy ML Solutions   ┆ this is the fifth video in a │\n",
      "│             ┆                      ┆ wit…                         ┆ l…                           │\n",
      "│ 6qCrvlHRhcM ┆ 2024-05-11T15:00:08Z ┆ How to Build ML Solutions    ┆ this is the fourth video in  │\n",
      "│             ┆                      ┆ (w/ …                        ┆ a …                          │\n",
      "│ OnIQrDiTtRM ┆ 2024-05-03T12:40:43Z ┆ How to Build Data Pipelines  ┆ when you think of machine    │\n",
      "│             ┆                      ┆ fo…                          ┆ lear…                        │\n",
      "│ eayzAZltV9U ┆ 2024-04-29T13:54:55Z ┆ 4 Lessons from AI Consulting ┆ are four things I've learned │\n",
      "│             ┆                      ┆ #…                           ┆ f…                           │\n",
      "│ 03x2oYg9oME ┆ 2024-04-25T15:16:00Z ┆ How to Manage Data Science   ┆ this video is part of a      │\n",
      "│             ┆                      ┆ Pro…                         ┆ larger…                      │\n",
      "└─────────────┴──────────────────────┴──────────────────────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# add transcripts to dataframe\n",
    "df = df.with_columns(pl.Series(name=\"transcript\", values=transcript_text_list))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (87, 4)\n",
      "n unique rows: 87\n",
      "n unique elements (video_id): 87\n",
      "n unique elements (datetime): 87\n",
      "n unique elements (title): 87\n",
      "n unique elements (transcript): 85\n"
     ]
    }
   ],
   "source": [
    "# shape + unique values\n",
    "print(\"shape:\", df.shape)\n",
    "print(\"n unique rows:\", df.n_unique())\n",
    "for j in range(df.shape[1]):\n",
    "    print(\"n unique elements (\" + df.columns[j] + \"):\", df[:,j].n_unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────┬─────────────────────┬───────────────────────────────┬──────────────────────────────┐\n",
      "│ video_id    ┆ datetime            ┆ title                         ┆ transcript                   │\n",
      "│ ---         ┆ ---                 ┆ ---                           ┆ ---                          │\n",
      "│ str         ┆ datetime[μs]        ┆ str                           ┆ str                          │\n",
      "╞═════════════╪═════════════════════╪═══════════════════════════════╪══════════════════════════════╡\n",
      "│ pJ_nCklQ65w ┆ 2024-05-18 15:24:22 ┆ How to Deploy ML Solutions    ┆ this is the fifth video in a │\n",
      "│             ┆                     ┆ wit…                          ┆ l…                           │\n",
      "│ 6qCrvlHRhcM ┆ 2024-05-11 15:00:08 ┆ How to Build ML Solutions (w/ ┆ this is the fourth video in  │\n",
      "│             ┆                     ┆ …                             ┆ a …                          │\n",
      "│ OnIQrDiTtRM ┆ 2024-05-03 12:40:43 ┆ How to Build Data Pipelines   ┆ when you think of machine    │\n",
      "│             ┆                     ┆ fo…                           ┆ lear…                        │\n",
      "│ eayzAZltV9U ┆ 2024-04-29 13:54:55 ┆ 4 Lessons from AI Consulting  ┆ are four things I've learned │\n",
      "│             ┆                     ┆ #…                            ┆ f…                           │\n",
      "│ 03x2oYg9oME ┆ 2024-04-25 15:16:00 ┆ How to Manage Data Science    ┆ this video is part of a      │\n",
      "│             ┆                     ┆ Pro…                          ┆ larger…                      │\n",
      "└─────────────┴─────────────────────┴───────────────────────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# change datetime to Datetime dtype\n",
    "df = df.with_columns(pl.col('datetime').cast(pl.Datetime))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all special strings and their replacements\n",
    "special_strings = ['&#39;', '&amp;', 'sha ']\n",
    "special_strings_replacements = [\"'\", \"&\", \"Shaw \"]\n",
    "\n",
    "# replace each special string appearing in title and transcript columns\n",
    "for i in range(len(special_strings)):\n",
    "    df = df.with_columns(df['title'].str.replace(special_strings[i],\n",
    "                        special_strings_replacements[i]).alias('title'))\n",
    "    df = df.with_columns(df['transcript'].str.replace(special_strings[i],\n",
    "                        special_strings_replacements[i]).alias('transcript'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to file\n",
    "pl.DataFrame(video_record_list).write_parquet('data/video-ids.parquet')\n",
    "pl.DataFrame(video_record_list).write_csv('data/video-ids.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
